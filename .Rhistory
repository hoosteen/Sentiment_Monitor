install.library(XML)
install.libraries(XML)
library(XML)
install.packages(XML)
install.packages("XML")
library(RCurl)
library(XML)
theurl <- "http://en.wikipedia.org/wiki/Congressional_Black_Caucus#Members_of_the_caucus_during_the_113th_Congress"
webpage <- getURL(theurl)
webpage <- readLines(tc <- textConnection(webpage)); close(tc)
pagetree <- htmlTreeParse(webpage, error=function(...){})
body <- pagetree$children$html$children$body
divbodyContent <- body$children$div$children[[1]]$children$div$children[[4]]
tables <- divbodyContent$children[names(divbodyContent)=="table"]
tableclasses <- sapply(tables, function(x) x$attributes["class"])
thetable  <- tables[which(tableclasses=="wikitable sortable")]$table
headers <- thetable$children[[1]]$children
columnnames <- unname(sapply(headers, function(x) x$children$text$value))
content <- c()
for(i in 2:length(thetable$children))
{
tablerow <- thetable$children[[i]]$children
opponent <- tablerow[[1]]$children[[2]]$children$text$value
others <- unname(sapply(tablerow[-1], function(x) x$children$text$value))
content <- rbind(content, c(opponent, others))
}
as.data.frame(content)
colnames(content) <- columnnames
as.data.frame(content)
head(content)
setwd("~/GitHub/ShameVector")
searchresults.df <- do.call(rbind, lapply(BB, as.data.frame))
?match.names
??match.names
View(BB.keeps)
View(BB.score)
library("twitteR")
library("RCurl")
library("RColorBrewer")
library("tm")
library("wordcloud")
library("httpuv")
library("tm")
library("dplyr")
wydenSearch <- read.csv("~/GitHub/ShameVector/wydenSearch.csv")
View(wydenSearch)
require("tm")
searchresults <- wydenSearch
searchresults_list <- sapply(searchresults, function(x) x$getText)
??getText
searchresults_list <- sapply(searchresults, function(x))
searchresults_list <- sapply(searchresults, function(x) x$getText())
searchresults_corpus <- Corpus(VectorSource(searchresults))
View(searchresults_corpus)
searchresults_corpus <- tm_map(searchresults_corpus, tolower)
searchresults_corpus <- tm_map(searchresults_corpus, removePunctuation)
searchresults_corpus <- tm_map(searchresults_corpus, function(x) removeWords(x, stopwords()))
wordcloud(searchresults_corpus, scale=c(5,0.5), max.words=100,
random.order=FALSE, rot.per=0.35,
use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
searchresults_list <- sapply(searchresults, function(x) x$getText())
searchresults_list <- sapply(searchresults, function(x) getText())
searchresults_list <- sapply(searchresults, function(x) x$getText())
searchresults_list <- sapply(searchresults, function(x) getText())
length(searchresults)
searchresults.df <- do.call(Rbind, lapply(searchresults, as.data.frame))
searchresults.df <- do.call(rbind, lapply(searchresults, as.data.frame))
searchresults.df <- tolower(searchresults.df)
searchresults.df <- searchresults
searchresults.df <- tolower(searchresults.df)
View(searchresults.df)
View(searchresults)
require(dplyr)
select(searchresults, text)
View(searchresults_corpus)
bad <- is.na(searchresults)
TPP[bad]
searchresults[bad]
View(searchresults)
searchresults$text <- gsub('[[:punct:]]', ' ', searchresults$text)
searchresult$text <- gsub('[[:cntrl:]]', '', searchresults$text)
searchresults$text <- gsub('[[:cntrl:]]', '', searchresults$text)
searchresults$text <- gsub('//d+', )
searchresults$text <- gsub('//d+', '', searchresults$text)
searchresults.text <- as.data.frame(searchresults$text)
searchresults.sn <- searchresults$screenName
searchresults_corpus <- Corpus(VectorSource(searchresults.text))
searchresults.text_stm <- tm_map(searchresults_corpus, stemDocument)
require(SnowballC)
searchresults.text_stm <- tm_map(searchresults_corpus, stemDocument)
stnd.stopwords<- stopwords("SMART")
searchresults.tf <- list(weighting = weightTf,
stopwords = stnd.stopwords,
removePunctuation = TRUE,
tolower = TRUE,
minWordLength = 4,
removeNumbers = TRUE)
summary(searchresults)
class(searchresults)
dim(searchresults)
class(searchresults_corpus)
dim(searchresults_corpus)
summary(searchresults_corpus
)
searchresults.text_stm <- tm_map(searchresults_corpus, stemDocument)
library("tm")
searchresults_corpus <- Corpus(VectorSource(searchresults.text))
searchresults_corpus <- tm_map(searchresults_corpus, tolower)
searchresults_corpus <- tm_map(searchresults_corpus, removePunctuation)
searchresults_corpus <- tm_map(searchresults_corpus, function(x) removeWords(x, stopwords()))
searchresults.text_stm <- tm_map(searchresults_corpus, stemDocument)
installed.packages("SnowballC")
install.packages("SnowballC")
require(SnowballC)
searchresults.text_stm <- tm_map(searchresults_corpus, stemDocument)
require(SnowballC)
library("twitteR")
library("RCurl")
library("RColorBrewer")
library("tm")
library("wordcloud")
library("httpuv")
library("dplyr")
searchresults.text_stm <- tm_map(searchresults_corpus, stemDocument)
stnd.stopwords<- stopwords("SMART")
searchresults.tf <- list(weighting = weightTf,
stopwords = stnd.stopwords,
removePunctuation = TRUE,
tolower = TRUE,
minWordLength = 4,
removeNumbers = TRUE)
searchresults_tdm <- TermDocumentMatrix(searchresults_corpus,
control = searchresults.tf)
class(searchresults_corpus)
searchresults_corpus_text <- tm_map(searchresults_corpus, PlainTextDocument)
searchresults_tdm <- TermDocumentMatrix(searchresults_corpus_text,
control = searchresults.tf)
sr.frequent <- sort(rowSums(as.matrix(searchresults_tdm)),
decreasing = TRUE)
sr.frequent[1:30]
library("twitteR")
library("RCurl")
library("RColorBrewer")
library("tm")
library("wordcloud")
library("httpuv")
library("dplyr")
library("SnowballC")
download.file(url="http://curl.haxx.se/ca/cacert.pem",
destfile="C:/Users/Justin/Documents/GitHub/ShameVector/Utilities/cacert.pem")
consumerKey <- "K2mpLnVJuDXlSqvC8KzaWgP5P"
consumerSecret <- "uzBix30ghVTFEciPOg3kuJLnZ4Kp2CaSJGl0FnIFNFOPBhkCn0"
access_token <- "14313727-hBhnH9BGe6hqV6nrhUyrUZ5hUi4IQmRW8zYVJgP0C"
access_token_secret <- "ZrOdr8Dv3k4wwEaOEs52hRkYTaFRoodvyfPXxfw6i8Aqa"
requestURL='https://api.twitter.com/oauth/request_token'
accessURL='https://api.twitter.com/oauth/access_token'
authURL='https://api.twitter.com/oauth/authorize'
twittercreds <- setup_twitter_oauth(consumerKey, consumerSecret)
save(twittercreds, file="twitter authentication data.Rdata")
searchresults <- searchTwitter("#WalterScott", n=2480)
searchresults.df <- do.call(rbind,
lapply(searchresults, as.data.frame))
write.csv(searchresults.df, "~/GitHub/ShameVector/TestData/WalterScott.csv")
searchresults_list <- sapply(searchresults, function(x) x$getText())
NAs <- is.na(searchresults)
searchresults[NAs]
searchresults$text <- gsub('[[:punct:]]', ' ', searchresults$text)
searchresults$text <- gsub('[[:cntrl:]]', ' ', searchresults$text)
# gsub subs numerical values with digits >=1 w/' '
searchresults$text <- gsub('//d+', ' ', searchresults$text)
## ///////CLEANING DATA WITH SHUFFLING/////// ##
# simplify the data frame by keeping the cleaned text,
# and other desired columns
searchresults.text <- as.data.frame(searchresults$text)
searchresults.sn <- searchresults$screenName
searchresults_corpus <- Corpus(VectorSource(searchresults.text))
searchresults_corpus <- tm_map(searchresults_corpus, tolower)
searchresults_corpus <- tm_map(searchresults_corpus, removePunctuation)
searchresults_corpus <- tm_map(searchresults_corpus, function(x) removeWords(x, stopwords()))
searchresults.text_stm <- tm_map(searchresults_corpus, stemDocument)
stnd.stopwords<- stopwords("SMART")
searchresults.tf <- list(weighting = weightTf,
stopwords = stnd.stopwords,
removePunctuation = TRUE,
tolower = TRUE,
minWordLength = 4,
removeNumbers = TRUE)
searchresults_corpus_text <- tm_map(searchresults_corpus, PlainTextDocument)
searchresults_tdm <- TermDocumentMatrix(searchresults_corpus_text,
control = searchresults.tf)
sr.frequent <- sort(rowSums(as.matrix(searchresults_tdm)),
decreasing = TRUE)
sr.frequent[1:30]
findFreqTerms(LPD_tdm, lowfreq = 60)
findFreqTerms(LPD_tdm, lowfreq = 60)
findFreqTerms(searchresults_tdm, lowfreq = 60)
pos.words<- c(pos_all, "spend", "buy", "earn", "hike", "increase",
"increases", "development", "expansion", "raise", "surge", "add",
"added", "advanced", "advances", "boom", "boosted", "boosting",
"waxed", "upbeat", "surge")
searchresults_corpus.95 <- removeSparseTerms(searchresults_tdm, .95)
searchresults.rsums <- sort(rowSums(as.matrix(searchresults.95)),
decreasing=TRUE)
searchresults.rsums <- sort(rowSums(as.matrix(searchresults_corpus.95)),
decreasing=TRUE)
searchresults.rsums <- data.frame(word=names(searchresults.rsums),
freq=searchresults.rsums)
palette <- brewer.pal(9, "BuGn")
palette <- palette[-(1:2)]
png(filename="~/cloud.png")
searchresults.wordcloud <- wordcloud(searchresults.rsums$word, searchresults.rsums$freq,
random.order=FALSE, colors=palette)
searchresults.wordcloud <- wordcloud(searchresults.rsums$word, searchresults.rsums$freq,
random.order=FALSE, colors=palette)
??wordcloud
View(searchresults.rsums)
View(searchresults.text)
View(searchresults.df)
library("twitteR")
library("RCurl")
library("RColorBrewer")
library("tm")
library("wordcloud")
library("httpuv")
library("dplyr")
library("SnowballC")
download.file(url="http://curl.haxx.se/ca/cacert.pem",
destfile="C:/Users/Justin/Documents/GitHub/ShameVector/Utilities/cacert.pem")
install.packages("RJSONIO")
